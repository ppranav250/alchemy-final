import asyncio
import os
import json
from pathlib import Path
import warnings
import weave

# MoviePy imports
from moviepy import VideoFileClip, AudioFileClip, concatenate_videoclips, ImageClip

# Local imports
from config_gen import generate_video_config_with_smart_docs
from manim_generator import generate_manim_clips
from voice_gen_fallback import generate_voice_with_fallback as generate_voice
from veo_gen import generate_veo_thank_you_clip


@weave.op()
def combine_video_with_audio_sync(video_path: str, audio_path: str, output_path: str) -> str:
    """Combine video with audio using MoviePy with extensive logging."""
    print(f"\nğŸ”— AUDIO-VIDEO COMBINATION DEBUG:")
    print(f"ğŸ“¹ Video path: {video_path}")
    print(f"ğŸµ Audio path: {audio_path}")
    print(f"ğŸ“ Output path: {output_path}")
    
    # Verify input files exist and are valid
    if not os.path.exists(video_path):
        print(f"âŒ ERROR: Video file does not exist: {video_path}")
        return video_path
    if not os.path.exists(audio_path):
        print(f"âŒ ERROR: Audio file does not exist: {audio_path}")
        return video_path
        
    print(f"ğŸ“Š Video file size: {os.path.getsize(video_path)} bytes")
    print(f"ğŸ“Š Audio file size: {os.path.getsize(audio_path)} bytes")
    
    try:
        print("ğŸ¬ Loading video clip...")
        video = VideoFileClip(video_path)
        print(f"âœ… Video loaded: {video.duration:.2f}s, {video.size}, {video.fps}fps")
        print(f"ğŸ”Š Video has audio: {video.audio is not None}")
        
        print("ğŸµ Loading audio clip...")
        audio = AudioFileClip(audio_path)
        print(f"âœ… Audio loaded: {audio.duration:.2f}s")
        print(f"ğŸ“Š Audio properties: {audio.fps}Hz, {audio.nchannels} channels")
        
        # Check duration mismatch
        duration_diff = abs(audio.duration - video.duration)
        print(f"â±ï¸  Duration difference: {duration_diff:.2f}s")
        
        # If audio is longer than video, extend video
        if audio.duration > video.duration:
            extra_duration = audio.duration - video.duration
            print(f"ğŸ”„ Extending video by {extra_duration:.2f}s to match audio")
            last_frame = video.get_frame(video.duration - 0.01)
            still_clip = ImageClip(last_frame, duration=(extra_duration + 0.1))
            extended_video = concatenate_videoclips([video, still_clip])
            print(f"âœ… Video extended to {extended_video.duration:.2f}s")
            final_video = extended_video.with_audio(audio)
        else:
            print("ğŸ”— Attaching audio to video...")
            final_video = video.with_audio(audio)
        
        print(f"âœ… Final video created: {final_video.duration:.2f}s")
        print(f"ğŸ”Š Final video has audio: {final_video.audio is not None}")
        
        print(f"ğŸ’¾ Writing video file to: {output_path}")
        final_video.write_videofile(
            output_path, 
            logger=None, 
            audio=True,  # Explicitly enable audio
            audio_codec='aac',  # Specify audio codec
            codec='libx264',  # Specify video codec
            temp_audiofile='temp-audio.m4a',  # Specify temp audio file
            remove_temp=True
        )
        
        # Verify output file
        if os.path.exists(output_path):
            output_size = os.path.getsize(output_path)
            print(f"âœ… Output file created: {output_size} bytes")
            
            # Test if output has audio
            test_clip = VideoFileClip(output_path)
            print(f"ğŸ”Š Output file has audio: {test_clip.audio is not None}")
            if test_clip.audio:
                print(f"ğŸ“Š Output audio duration: {test_clip.audio.duration:.2f}s")
            test_clip.close()
        else:
            print(f"âŒ ERROR: Output file was not created")
        
        # Clean up
        print("ğŸ§¹ Cleaning up resources...")
        video.close()
        audio.close()
        final_video.close()
        if 'extended_video' in locals():
            extended_video.close()
        
        print(f"âœ… Audio-video combination completed successfully\n")
        return output_path
    except Exception as e:
        print(f"âŒ ERROR in audio-video combination: {e}")
        import traceback
        print(f"ğŸ“‹ Traceback: {traceback.format_exc()}")
        return video_path


@weave.op()
def normalize_video_clip(clip, target_fps: int = 24, target_resolution: tuple = (1280, 720)) -> VideoFileClip:
    """
    Normalize video clip to consistent format for stitching.
    
    Args:
        clip: VideoFileClip to normalize
        target_fps: Target frame rate (Veo uses 24fps)
        target_resolution: Target resolution (width, height) - Veo uses 720p
    
    Returns:
        Normalized VideoFileClip
    """
    try:
        # Store original audio if present
        original_audio = clip.audio
        had_audio = original_audio is not None
        
        # Get current dimensions
        current_w, current_h = clip.size
        target_w, target_h = target_resolution
        
        # Resize if needed (maintain aspect ratio)
        if (current_w, current_h) != (target_w, target_h):
            print(f"ğŸ“ Resizing clip from {current_w}x{current_h} to {target_w}x{target_h}")
            clip = clip.resized(newsize=(target_w, target_h))
        
        # Adjust frame rate if needed
        if abs(clip.fps - target_fps) > 0.1:  # Small tolerance for floating point
            print(f"ğŸ¬ Adjusting frame rate from {clip.fps}fps to {target_fps}fps")
            clip = clip.with_fps(target_fps)
        
        # Restore audio if it was lost during transformation but was originally present
        if had_audio and clip.audio is None:
            print("ğŸ“¢ Restoring lost audio after transformation")
            clip = clip.with_audio(original_audio)
        
        return clip
        
    except Exception as e:
        print(f"âš ï¸  Warning: Could not normalize clip - {e}")
        return clip

@weave.op()
def stitch_videos(video_paths: list, output_path: str = "summary_video.mp4", add_thank_you: bool = True) -> str:
    """Stitch multiple video files together with optional Veo 'Thank You' ending."""
    print(f"\nğŸ¬ VIDEO STITCHING DEBUG:")
    print(f"ğŸ“ Input paths: {len(video_paths)} videos")
    print(f"ğŸ“ Output path: {output_path}")
    print(f"ğŸ™ Add thank you: {add_thank_you}")
    
    try:
        clips = []
        print("ğŸ”§ Loading and normalizing video clips...")
        
        for i, path in enumerate(video_paths):
            if os.path.exists(path):
                print(f"\nğŸ“¹ Processing clip {i+1}/{len(video_paths)}: {os.path.basename(path)}")
                print(f"ğŸ“ File size: {os.path.getsize(path)} bytes")
                
                clip = VideoFileClip(path)
                print(f"â±ï¸  Clip duration: {clip.duration:.2f}s")
                print(f"ğŸ“ Clip size: {clip.size}")
                print(f"ğŸ¬ Clip FPS: {clip.fps}")
                print(f"ğŸ”Š Clip has audio: {clip.audio is not None}")
                if clip.audio:
                    print(f"ğŸµ Audio duration: {clip.audio.duration:.2f}s")
                    print(f"ğŸ”ˆ Audio channels: {clip.audio.nchannels}")
                
                # Normalize each clip to ensure consistent format
                print(f"ğŸ”„ Normalizing clip {i+1}...")
                normalized_clip = normalize_video_clip(clip)
                print(f"âœ… Normalized clip {i+1}:")
                print(f"  ğŸ”Š Has audio after normalization: {normalized_clip.audio is not None}")
                if normalized_clip.audio:
                    print(f"  ğŸµ Audio duration after normalization: {normalized_clip.audio.duration:.2f}s")
                
                clips.append(normalized_clip)
                
                # Close original clip to free memory
                if normalized_clip != clip:
                    clip.close()
            else:
                print(f"âŒ Clip {i+1} not found: {path}")
        
        if not clips:
            print("âŒ ERROR: No valid video clips found")
            raise ValueError("No valid video clips found")
        
        print(f"\nğŸ“Š CLIPS SUMMARY BEFORE STITCHING:")
        total_duration = 0
        clips_with_audio = 0
        for i, clip in enumerate(clips):
            has_audio = clip.audio is not None
            duration = clip.duration
            total_duration += duration
            if has_audio:
                clips_with_audio += 1
            print(f"  Clip {i+1}: {duration:.2f}s, audio={has_audio}")
        print(f"  Total duration: {total_duration:.2f}s")
        print(f"  Clips with audio: {clips_with_audio}/{len(clips)}")
        
        # Add Veo "Thank You" clip at the end
        if add_thank_you:
            print("\nğŸ¬ Adding Veo 'Thank You' clip to the end...")
            try:
                # Use the thank you clip with audio if available, otherwise generate new one
                if os.path.exists("clips/thank_you_with_audio.mp4"):
                    veo_clip_path = "clips/thank_you_with_audio.mp4"
                    print(f"ğŸ“ Using existing thank you clip: {veo_clip_path}")
                else:
                    thank_you_path = "clips/thank_you_veo.mp4"
                    print(f"ğŸ¬ Generating new thank you clip...")
                    veo_clip_path = generate_veo_thank_you_clip(thank_you_path)
                
                if veo_clip_path and os.path.exists(veo_clip_path):
                    print(f"ğŸ“¹ Processing Veo 'Thank You' clip: {veo_clip_path}")
                    print(f"ğŸ“ Thank you file size: {os.path.getsize(veo_clip_path)} bytes")
                    
                    thank_you_clip = VideoFileClip(veo_clip_path)
                    print(f"â±ï¸  Thank you duration: {thank_you_clip.duration:.2f}s")
                    print(f"ğŸ”Š Thank you has audio: {thank_you_clip.audio is not None}")
                    
                    # Normalize the Veo clip to match other clips
                    print(f"ğŸ”„ Normalizing thank you clip...")
                    normalized_thank_you = normalize_video_clip(thank_you_clip)
                    print(f"âœ… Thank you normalized: audio={normalized_thank_you.audio is not None}")
                    clips.append(normalized_thank_you)
                    
                    # Close original if different
                    if normalized_thank_you != thank_you_clip:
                        thank_you_clip.close()
                    
                    print("âœ… Veo 'Thank You' clip added and normalized!")
                else:
                    print("âš ï¸  Veo clip generation failed, continuing without thank you")
                    
            except Exception as e:
                print(f"âš ï¸  Could not add Veo thank you clip: {e}")
                import traceback
                print(f"ğŸ“‹ Traceback: {traceback.format_exc()}")
        
        # Final clips summary
        print(f"\nğŸ“Š FINAL CLIPS SUMMARY (including thank you):")
        final_total_duration = 0
        final_clips_with_audio = 0
        for i, clip in enumerate(clips):
            has_audio = clip.audio is not None
            duration = clip.duration
            final_total_duration += duration
            if has_audio:
                final_clips_with_audio += 1
            print(f"  Final clip {i+1}: {duration:.2f}s, audio={has_audio}")
        print(f"  Final total duration: {final_total_duration:.2f}s")
        print(f"  Final clips with audio: {final_clips_with_audio}/{len(clips)}")
        
        # Concatenate all clips (main content + thank you)
        print(f"\nğŸ”— CONCATENATING CLIPS...")
        print(f"ğŸ“ Concatenating {len(clips)} clips using 'chain' method")
        final_clip = concatenate_videoclips(clips, method="chain")
        print(f"âœ… Concatenation complete:")
        print(f"  â±ï¸  Final duration: {final_clip.duration:.2f}s")
        print(f"  ğŸ”Š Final clip has audio: {final_clip.audio is not None}")
        if final_clip.audio:
            print(f"  ğŸµ Final audio duration: {final_clip.audio.duration:.2f}s")
            print(f"  ğŸ”ˆ Final audio channels: {final_clip.audio.nchannels}")
        
        # Write final video with explicit audio settings
        print(f"\nğŸ’¾ WRITING FINAL VIDEO...")
        print(f"ğŸ“ Output path: {output_path}")
        final_clip.write_videofile(
            output_path, 
            logger=None, 
            audio=True,  # Explicitly enable audio
            audio_codec='aac',  # Specify audio codec
            codec='libx264',  # Specify video codec
            temp_audiofile='temp-final-audio.m4a',  # Specify temp audio file
            remove_temp=True,
            audio_fps=44100  # Ensure consistent audio sample rate
        )
        
        # Verify final output
        if os.path.exists(output_path):
            output_size = os.path.getsize(output_path)
            print(f"âœ… Final video written: {output_size} bytes")
            
            # Test final output audio
            print(f"ğŸ§ª Testing final output audio...")
            test_final = VideoFileClip(output_path)
            print(f"  ğŸ”Š Final output has audio: {test_final.audio is not None}")
            if test_final.audio:
                print(f"  ğŸµ Final output audio duration: {test_final.audio.duration:.2f}s")
                print(f"  ğŸ”ˆ Final output audio channels: {test_final.audio.nchannels}")
            test_final.close()
        else:
            print(f"âŒ ERROR: Final video file was not created")
        
        # Clean up
        print(f"\nğŸ§¹ Cleaning up resources...")
        final_clip.close()
        for i, clip in enumerate(clips):
            print(f"  ğŸ—‘ï¸  Closing clip {i+1}")
            clip.close()
        
        print(f"âœ… VIDEO STITCHING COMPLETED SUCCESSFULLY\n")
        return output_path
    except Exception as e:
        print(f"âŒ ERROR in video stitching: {e}")
        import traceback
        print(f"ğŸ“‹ Full traceback: {traceback.format_exc()}")
        raise


@weave.op()
async def generate_summary_video_upload(pdf_path: str, user_prompt: str = "") -> dict:
    """Generate a 1-minute summary video from an uploaded PDF file."""
    print(f"ğŸ“„ Processing uploaded PDF: {pdf_path}")
    print(f"ğŸ“ User prompt: {user_prompt}")
    
    # Generate video config from PDF using base64 encoding
    response = generate_video_config_with_smart_docs(pdf_path, user_prompt, use_base64=True)
    config_text = response.content[0].text
    
    # Parse JSON config
    try:
        config = json.loads(config_text)
    except json.JSONDecodeError:
        import re
        json_match = re.search(r'\{.*\}', config_text, re.DOTALL)
        if json_match:
            config = json.loads(json_match.group())
        else:
            raise ValueError("Could not parse video configuration")
    
    clips = config.get("clips", [])
    if not clips:
        raise ValueError("No clips generated from PDF")
    
    # Limit to ~1 minute (take first few clips)
    max_clips = min(len(clips), 4)  # Roughly 4 clips for 1 minute
    clips = clips[:max_clips]
    
    print(f"ğŸ¬ Generating {len(clips)} video clips...")
    
    # Generate Manim videos
    output_dir = "clips"
    os.makedirs(output_dir, exist_ok=True)
    
    video_paths = await generate_manim_clips(clips, output_dir, "medium_quality")
    
    # Track video generation metrics
    successful_clips = 0
    failed_clips = 0
    
    # Add voice-over to each clip (with fallback to silent video)
    print(f"\nğŸ¤ ADDING VOICE-OVER TO CLIPS...")
    final_clips = []
    for i, (clip_config, video_path) in enumerate(zip(clips, video_paths)):
        print(f"\nğŸ¬ Processing clip {i+1}/{len(clips)}...")
        print(f"ğŸ“ Video path: {video_path}")
        
        if video_path:
            # Verify video file exists and is valid
            if not os.path.exists(video_path):
                print(f"âŒ Clip {i+1} video file not found: {video_path}")
                failed_clips += 1
                continue
                
            video_size = os.path.getsize(video_path)
            print(f"ğŸ“ Video file size: {video_size} bytes")
            
            # Try to generate voice-over, but continue if it fails
            try:
                voice_text = clip_config.get('voice_over')
                if voice_text:
                    print(f"ğŸ¤ Generating voice for clip {i+1}...")
                    print(f"ğŸ“ Voice text: {voice_text[:100]}...")
                    
                    audio_path = f"{output_dir}/audio_{i}.wav"
                    print(f"ğŸ“ Audio output path: {audio_path}")
                    
                    audio_result = await generate_voice(voice_text, audio_path)
                    print(f"ğŸ“ Voice generation result: {audio_result}")
                    
                    if audio_result and os.path.exists(audio_result):
                        audio_size = os.path.getsize(audio_result)
                        print(f"âœ… Audio generated: {audio_size} bytes")
                        
                        final_path = f"{output_dir}/final_{i}.mp4"
                        print(f"ğŸ”— Combining video + audio -> {final_path}")
                        
                        combined_path = combine_video_with_audio_sync(video_path, audio_path, final_path)
                        
                        if combined_path and os.path.exists(combined_path):
                            combined_size = os.path.getsize(combined_path)
                            print(f"âœ… Combined video created: {combined_size} bytes")
                            
                            # Verify combined video has audio
                            try:
                                test_combined = VideoFileClip(combined_path)
                                has_audio = test_combined.audio is not None
                                print(f"ğŸ”Š Combined video has audio: {has_audio}")
                                test_combined.close()
                            except Exception as test_e:
                                print(f"âš ï¸  Could not test combined video: {test_e}")
                            
                            final_clips.append(combined_path)
                            successful_clips += 1
                            print(f"âœ“ Clip {i+1} with voice-over completed")
                        else:
                            print(f"âš ï¸  Audio combination failed, using silent video")
                            final_clips.append(video_path)
                            successful_clips += 1
                            print(f"âœ“ Clip {i+1} (silent - combination failed)")
                    else:
                        print(f"âš ï¸  Voice generation failed, using silent video")
                        final_clips.append(video_path)
                        successful_clips += 1
                        print(f"âœ“ Clip {i+1} (silent - voice failed)")
                else:
                    print(f"ğŸ”‡ No voice text provided for clip {i+1}")
                    final_clips.append(video_path)
                    successful_clips += 1
                    print(f"âœ“ Clip {i+1} (silent - no voice text)")
            except Exception as e:
                print(f"âŒ Voice generation failed for clip {i+1}: {e}")
                import traceback
                print(f"ğŸ“‹ Traceback: {traceback.format_exc()}")
                final_clips.append(video_path)
                successful_clips += 1
                print(f"âœ“ Clip {i+1} (silent - voice failed with exception)")
        else:
            failed_clips += 1
            print(f"âœ— Clip {i+1} failed to generate (no video path)")
    
    print(f"\nğŸ“Š VOICE-OVER PROCESSING SUMMARY:")
    print(f"  âœ… Successful clips: {successful_clips}")
    print(f"  âŒ Failed clips: {failed_clips}")
    print(f"  ğŸ“ Final clips ready: {len(final_clips)}")
    
    # Critical audio verification 
    clips_with_audio = 0
    clips_without_audio = 0
    for i, clip_path in enumerate(final_clips):
        try:
            test_clip = VideoFileClip(clip_path)
            has_audio = test_clip.audio is not None
            if has_audio:
                clips_with_audio += 1
                print(f"  ğŸ”Š Clip {i+1}: HAS AUDIO ({clip_path})")
            else:
                clips_without_audio += 1
                print(f"  ğŸ”‡ Clip {i+1}: NO AUDIO ({clip_path})")
            test_clip.close()
        except Exception as e:
            print(f"  âŒ Clip {i+1}: ERROR checking audio ({e})")
            clips_without_audio += 1
    
    print(f"\nğŸµ AUDIO VERIFICATION:")
    print(f"  ğŸ“Š Clips with audio: {clips_with_audio}/{len(final_clips)}")
    print(f"  ğŸ“Š Clips without audio: {clips_without_audio}/{len(final_clips)}")
    
    if clips_without_audio > 0:
        print(f"\nâš ï¸ WARNING: {clips_without_audio} clips have no audio!")
        print(f"ğŸ”§ This will result in a video with missing audio segments.")
        if clips_with_audio == 0:
            print(f"ğŸš¨ CRITICAL: ALL CLIPS ARE SILENT!")
    
    if not final_clips:
        print("âŒ CRITICAL ERROR: No clips were successfully generated")
        raise ValueError("No clips were successfully generated")
    
    # Stitch all clips together
    final_video = stitch_videos(final_clips, "summary_video.mp4", add_thank_you=True)
    
    print(f"âœ… Summary video created: {final_video}")
    
    # Return comprehensive results for Weave tracking
    return {
        "video_path": final_video,
        "total_clips": len(clips),
        "successful_clips": successful_clips,
        "failed_clips": failed_clips,
        "success_rate": successful_clips / len(clips) if clips else 0,
        "pdf_path": pdf_path,
        "clips_config": clips
    }


@weave.op()
async def generate_summary_video(pdf_url: str, user_prompt: str = "") -> dict:
    """Generate a 1-minute summary video from a PDF URL."""
    print(f"ğŸ“„ Processing PDF: {pdf_url}")
    print(f"ğŸ“ User prompt: {user_prompt}")
    
    # Generate video config from PDF
    response = generate_video_config_with_smart_docs(pdf_url, user_prompt, use_base64=False)
    config_text = response.content[0].text
    
    # Parse JSON config
    try:
        config = json.loads(config_text)
    except json.JSONDecodeError:
        import re
        json_match = re.search(r'\{.*\}', config_text, re.DOTALL)
        if json_match:
            config = json.loads(json_match.group())
        else:
            raise ValueError("Could not parse video configuration")
    
    clips = config.get("clips", [])
    if not clips:
        raise ValueError("No clips generated from PDF")
    
    # Limit to ~1 minute (take first few clips)
    max_clips = min(len(clips), 4)  # Roughly 4 clips for 1 minute
    clips = clips[:max_clips]
    
    print(f"ğŸ¬ Generating {len(clips)} video clips...")
    
    # Generate Manim videos
    output_dir = "clips"
    os.makedirs(output_dir, exist_ok=True)
    
    video_paths = await generate_manim_clips(clips, output_dir, "medium_quality")
    
    # Track video generation metrics
    successful_clips = 0
    failed_clips = 0
    
    # Add voice-over to each clip (with fallback to silent video)
    print(f"\nğŸ¤ ADDING VOICE-OVER TO CLIPS...")
    final_clips = []
    for i, (clip_config, video_path) in enumerate(zip(clips, video_paths)):
        print(f"\nğŸ¬ Processing clip {i+1}/{len(clips)}...")
        print(f"ğŸ“ Video path: {video_path}")
        
        if video_path:
            # Verify video file exists and is valid
            if not os.path.exists(video_path):
                print(f"âŒ Clip {i+1} video file not found: {video_path}")
                failed_clips += 1
                continue
                
            video_size = os.path.getsize(video_path)
            print(f"ğŸ“ Video file size: {video_size} bytes")
            
            # Try to generate voice-over, but continue if it fails
            try:
                voice_text = clip_config.get('voice_over')
                if voice_text:
                    print(f"ğŸ¤ Generating voice for clip {i+1}...")
                    print(f"ğŸ“ Voice text: {voice_text[:100]}...")
                    
                    audio_path = f"{output_dir}/audio_{i}.wav"
                    print(f"ğŸ“ Audio output path: {audio_path}")
                    
                    audio_result = await generate_voice(voice_text, audio_path)
                    print(f"ğŸ“ Voice generation result: {audio_result}")
                    
                    if audio_result and os.path.exists(audio_result):
                        audio_size = os.path.getsize(audio_result)
                        print(f"âœ… Audio generated: {audio_size} bytes")
                        
                        final_path = f"{output_dir}/final_{i}.mp4"
                        print(f"ğŸ”— Combining video + audio -> {final_path}")
                        
                        combined_path = combine_video_with_audio_sync(video_path, audio_path, final_path)
                        
                        if combined_path and os.path.exists(combined_path):
                            combined_size = os.path.getsize(combined_path)
                            print(f"âœ… Combined video created: {combined_size} bytes")
                            
                            # Verify combined video has audio
                            try:
                                test_combined = VideoFileClip(combined_path)
                                has_audio = test_combined.audio is not None
                                print(f"ğŸ”Š Combined video has audio: {has_audio}")
                                test_combined.close()
                            except Exception as test_e:
                                print(f"âš ï¸  Could not test combined video: {test_e}")
                            
                            final_clips.append(combined_path)
                            successful_clips += 1
                            print(f"âœ“ Clip {i+1} with voice-over completed")
                        else:
                            print(f"âš ï¸  Audio combination failed, using silent video")
                            final_clips.append(video_path)
                            successful_clips += 1
                            print(f"âœ“ Clip {i+1} (silent - combination failed)")
                    else:
                        print(f"âš ï¸  Voice generation failed, using silent video")
                        final_clips.append(video_path)
                        successful_clips += 1
                        print(f"âœ“ Clip {i+1} (silent - voice failed)")
                else:
                    print(f"ğŸ”‡ No voice text provided for clip {i+1}")
                    final_clips.append(video_path)
                    successful_clips += 1
                    print(f"âœ“ Clip {i+1} (silent - no voice text)")
            except Exception as e:
                print(f"âŒ Voice generation failed for clip {i+1}: {e}")
                import traceback
                print(f"ğŸ“‹ Traceback: {traceback.format_exc()}")
                final_clips.append(video_path)
                successful_clips += 1
                print(f"âœ“ Clip {i+1} (silent - voice failed with exception)")
        else:
            failed_clips += 1
            print(f"âœ— Clip {i+1} failed to generate (no video path)")
    
    print(f"\nğŸ“Š VOICE-OVER PROCESSING SUMMARY:")
    print(f"  âœ… Successful clips: {successful_clips}")
    print(f"  âŒ Failed clips: {failed_clips}")
    print(f"  ğŸ“ Final clips ready: {len(final_clips)}")
    
    # Critical audio verification 
    clips_with_audio = 0
    clips_without_audio = 0
    for i, clip_path in enumerate(final_clips):
        try:
            test_clip = VideoFileClip(clip_path)
            has_audio = test_clip.audio is not None
            if has_audio:
                clips_with_audio += 1
                print(f"  ğŸ”Š Clip {i+1}: HAS AUDIO ({clip_path})")
            else:
                clips_without_audio += 1
                print(f"  ğŸ”‡ Clip {i+1}: NO AUDIO ({clip_path})")
            test_clip.close()
        except Exception as e:
            print(f"  âŒ Clip {i+1}: ERROR checking audio ({e})")
            clips_without_audio += 1
    
    print(f"\nğŸµ AUDIO VERIFICATION:")
    print(f"  ğŸ“Š Clips with audio: {clips_with_audio}/{len(final_clips)}")
    print(f"  ğŸ“Š Clips without audio: {clips_without_audio}/{len(final_clips)}")
    
    if clips_without_audio > 0:
        print(f"\nâš ï¸ WARNING: {clips_without_audio} clips have no audio!")
        print(f"ğŸ”§ This will result in a video with missing audio segments.")
        if clips_with_audio == 0:
            print(f"ğŸš¨ CRITICAL: ALL CLIPS ARE SILENT!")
    
    if not final_clips:
        print("âŒ CRITICAL ERROR: No clips were successfully generated")
        raise ValueError("No clips were successfully generated")
    
    # Stitch all clips together
    final_video = stitch_videos(final_clips, "summary_video.mp4", add_thank_you=True)
    
    print(f"âœ… Summary video created: {final_video}")
    
    # Return comprehensive results for Weave tracking
    return {
        "video_path": final_video,
        "total_clips": len(clips),
        "successful_clips": successful_clips,
        "failed_clips": failed_clips,
        "success_rate": successful_clips / len(clips) if clips else 0,
        "pdf_url": pdf_url,
        "clips_config": clips
    }


def main():
    """Simple main function - just ask for URL and generate video."""
    # Initialize Weave tracking (with fallback)
    try:
        weave.init("manim_video_generator")
        print("âœ… W&B Weave tracking initialized")
    except Exception as e:
        print(f"âš ï¸  W&B Weave not available: {e}")
        print("ğŸ“Š Running without tracking")
    
    print("ğŸ¬ PDF to Video Summary Generator")
    print("=" * 40)
    
    # Get PDF URL
    pdf_url = input("Enter PDF URL: ").strip()
    
    if not pdf_url:
        print("âŒ No URL provided")
        return
    
    if not pdf_url.startswith(('http://', 'https://')):
        print("âŒ Please provide a valid URL")
        return
    
    print(f"ğŸš€ Generating 1-minute summary video from: {pdf_url}")
    
    try:
        # Generate the video with full tracking
        result = asyncio.run(generate_summary_video(pdf_url))
        
        print(f"ğŸ‰ Done! Video saved as: {result['video_path']}")
        print(f"ğŸ“ Full path: {os.path.abspath(result['video_path'])}")
        print(f"ğŸ“Š Success rate: {result['success_rate']:.1%} ({result['successful_clips']}/{result['total_clips']} clips)")
        
    except Exception as e:
        print(f"âŒ Error: {e}")


if __name__ == "__main__":
    main() 